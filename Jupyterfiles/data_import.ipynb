{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'talib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24968/221744347.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtalib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtalib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmplfinance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moriginal_flavor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcandlestick_ohlc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'talib'"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import talib as talib\n",
    "from matplotlib import pyplot as plt\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "from matplotlib.pylab import date2num\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,BatchNormalization,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import list of top 100 stocks USA\n",
    "# import stock list from CSV file\n",
    "importedCsv = pd.read_csv (r'../CSV/StockList.csv', sep=',')\n",
    "print(importedCsv[\"Symbol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def checkNonesString(df):\n",
    "    # CHECK Object column for \"None\" strings.\n",
    "    print(df[df['Symbol'].str.contains('None')].any())\n",
    "    \n",
    "\n",
    "def checkNans(df):\n",
    "    # Check if there are NaNs\n",
    "    print(\"-----IS NA per COL-------\")\n",
    "    print(\"Doesn't seem to be working\")\n",
    "    print(df[df.isna().any(axis=1)].sum())\n",
    "\n",
    "    print(\"-----IS NA per COL-------\")\n",
    "    print(df.isna().sum())\n",
    "\n",
    "    print(\"------printing sum of Nans for each column------\")\n",
    "    for col in df.columns:\n",
    "        print(col + \": \" + str(df[col].isnull().sum()))\n",
    "\n",
    "def is_even(number):\n",
    "    \"\"\"Return whether an integer is even or not.\"\"\"\n",
    "    return 5      \n",
    "        \n",
    "def checkInfs(df):\n",
    "    print(\"-------total amount of Infs per Column-----------\")\n",
    "    print(df.groupby(np.isinf(df[\"Open\"])).count())\n",
    "\n",
    "    print(\"-------total amount of Infs-----------\")\n",
    "    count = np.isinf(df[\"Open\"]).values.sum()\n",
    "    print(\"It contains \" + str(count) + \" infinite values\")\n",
    "\n",
    "\n",
    "def printDataframe(df):\n",
    "    # Prints\n",
    "    print(\"-----DATAFRAME-------\")\n",
    "    print(df.head(10))\n",
    "\n",
    "    print(\"-----SHAPE-------\")\n",
    "    print(df.shape)\n",
    "\n",
    "    print(\"-----COLUMNS-------\")\n",
    "    print(df.columns)\n",
    "\n",
    "    print(\"-----DATATYPES-------\")\n",
    "    print(df.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Timestamp        Open        High         Low       Close  \\\n",
      "Date                                                                    \n",
      "1980-12-12 1980-12-12    0.100326    0.100762    0.100326    0.100326   \n",
      "1980-12-15 1980-12-15    0.095528    0.095528    0.095092    0.095092   \n",
      "1980-12-16 1980-12-16    0.088548    0.088548    0.088112    0.088112   \n",
      "1980-12-17 1980-12-17    0.090293    0.090729    0.090293    0.090293   \n",
      "1980-12-18 1980-12-18    0.092911    0.093347    0.092911    0.092911   \n",
      "...               ...         ...         ...         ...         ...   \n",
      "2022-02-09 2022-02-09  176.050003  176.649994  174.899994  176.279999   \n",
      "2022-02-10 2022-02-10  174.139999  175.479996  171.550003  172.119995   \n",
      "2022-02-11 2022-02-11  172.330002  173.080002  168.039993  168.639999   \n",
      "2022-02-14 2022-02-14  167.369995  169.580002  166.559998  168.880005   \n",
      "2022-02-15 2022-02-15  170.970001  172.360001  170.250000  171.970001   \n",
      "\n",
      "               Volume  Dividends  Stock Splits Symbol  \n",
      "Date                                                   \n",
      "1980-12-12  469033600        0.0           0.0   AAPL  \n",
      "1980-12-15  175884800        0.0           0.0   AAPL  \n",
      "1980-12-16  105728000        0.0           0.0   AAPL  \n",
      "1980-12-17   86441600        0.0           0.0   AAPL  \n",
      "1980-12-18   73449600        0.0           0.0   AAPL  \n",
      "...               ...        ...           ...    ...  \n",
      "2022-02-09   71285000        0.0           0.0   AAPL  \n",
      "2022-02-10   90865900        0.0           0.0   AAPL  \n",
      "2022-02-11   98566000        0.0           0.0   AAPL  \n",
      "2022-02-14   86062800        0.0           0.0   AAPL  \n",
      "2022-02-15   46447864        0.0           0.0   AAPL  \n",
      "\n",
      "[10383 rows x 9 columns]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'importedCsv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24968/1536910596.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0moneStockAAPL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Timestamp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moneStockAAPL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moneStockAAPL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimportedCsv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Symbol\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#add code for all stocks to ahve the same date interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'importedCsv' is not defined"
     ]
    }
   ],
   "source": [
    "# Add historical data for all stocks in ImportedCSV file = 100 stocks\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "oneStockAAPL = yf.Ticker(\"AAPL\").history(period=\"max\")\n",
    "# adding symbol for traceability\n",
    "oneStockAAPL[\"Symbol\"] = \"AAPL\"\n",
    "# Rearragning the date column to a functionalt \"timestamp\"\n",
    "#oneStockAAPL[\"Timestamp\"] = oneStockAAPL.index\n",
    "oneStockAAPL.insert(0, 'Timestamp', oneStockAAPL.index)\n",
    "print(oneStockAAPL)\n",
    "for col in importedCsv[\"Symbol\"]:\n",
    "    \n",
    "    #add code for all stocks to ahve the same date interval\n",
    "    \n",
    "    #fetch data for every stock\n",
    "    temp = yf.Ticker(col).history(period=\"max\")\n",
    "    # adding symbol for traceability\n",
    "    temp[\"Symbol\"] = col\n",
    "    # Rearragning the date column to a functionalt \"timestamp\"\n",
    "    temp[\"Timestamp\"] = temp.index\n",
    "    # concateing with the dataframe for all stocks\n",
    "    final_df = pd.concat([final_df, temp], axis=0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restting index\n",
    "oneStockAAPL.reset_index(drop=True, inplace=True)\n",
    "final_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking functions\n",
    "printDataframe(final_df)\n",
    "checkInfs(final_df)\n",
    "checkNans(final_df)\n",
    "checkNonesString(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the row witht the NaNs\n",
    "#df1 = final_df[final_df['Symbol'].str.contains(\"NVDA\")]\n",
    "#is_NaN = df1.isnull()\n",
    "#row_has_NaN = is_NaN.any(axis=1)\n",
    "#rows_with_NaN = df1[row_has_NaN]\n",
    "#print(rows_with_NaN)\n",
    "#print(df1)\n",
    "\n",
    "#print(\"--------\")\n",
    "#df2 = final_df.loc[46545:46550]\n",
    "#print(df2)\n",
    "\n",
    "# Dropping rows with NaNs, (should only be one in NVDA)\n",
    "final_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking functions\n",
    "printDataframe(final_df)\n",
    "checkInfs(final_df)\n",
    "checkNans(final_df)\n",
    "checkNonesString(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(oneStockAAPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get earliest timestamp for all stocks...\n",
    "\n",
    "print(min(oneStockAAPL['Timestamp']))\n",
    "print(max(oneStockAAPL['Timestamp']))\n",
    "printDataframe(oneStockAAPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneStockAAPL.to_csv(r'../CSV/oneStockAAPL.csv', sep= \",\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
